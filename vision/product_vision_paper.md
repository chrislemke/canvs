# CANVS - It's the world: The Spatial Social Layer

## Product Vision Paper & Strategic Roadmap

**Tagline:** *The end of the feed. The beginning of the world.*

---

## Table of Contents

- [0. Executive Summary: What CANVS Is](#0-executive-summary-what-canvs-is)
- [1. Manifesto: The End of the Feed, the Beginning of the World](#1-manifesto-the-end-of-the-feed-the-beginning-of-the-world)
- [2. The Problem: Context Loss and the "Ghost Event"](#2-the-problem-context-loss-and-the-ghost-event)
- [3. The Solution: Persistent Emotional Anchoring](#3-the-solution-persistent-emotional-anchoring)
- [4. The Product Thesis: "The Spatial Social Layer"](#4-the-product-thesis-the-spatial-social-layer)
- [5. Core Experience: The Spatial Browser](#5-core-experience-the-spatial-browser)
- [6. Core Building Blocks: Spatial Primitives](#6-core-building-blocks-spatial-primitives)
- [7. Deep-Tech Foundation: How This Becomes Real](#7-deep-tech-foundation-how-this-becomes-real)
- [8. Market Opportunity: Why This, Why Now](#8-market-opportunity-why-this-why-now)
- [9. Competitive Landscape](#9-competitive-landscape)
- [10. LLM Agents as the "Reality Filter"](#10-llm-agents-as-the-reality-filter-not-a-chatbot)
- [11. Emotional & Social Use Cases: Re-enchanting Reality](#11-emotional--social-use-cases-re-enchanting-reality)
- [12. Societal Impact: Why the World Needs This](#12-societal-impact-why-the-world-needs-this)
- [13. Challenges & Mitigations](#13-challenges--mitigations)
- [14. Trust, Safety, and Governance](#14-trust-safety-and-governance-the-layer-must-be-safe-by-design)
- [15. Monetization: Non-Intrusive, Spatial-Native, Opt-In](#15-monetization-non-intrusive-spatial-native-opt-in)
- [16. Strategic Roadmap: Mobile-First, Then Glass-Native](#16-strategic-roadmap-mobile-first-then-glass-native)
- [17. The Big Opportunity](#17-the-big-opportunity-why-this-can-become-a-once-a-decade-platform)
- [18. Conclusion: Build the Layer](#18-conclusion-build-the-layer)
- [Appendix A: Research Sources](#appendix-a-research-sources)

---

## 0. Executive Summary: What CANVS Is

CANVS is a **persistent, AR-native social layer anchored to physical places**. Instead of consuming life through a decontextualized feed, people experience content **where it belongs**: at the location it refers to, at the scale it happened, with the atmosphere that gave it meaning.

CANVS turns the planet into an **addressable surface**: every bench, alley, beach, mural, café table, trailhead, and plaza becomes a node in a living network of memories, knowledge, art, and coordination.

This idea is now feasible because the enabling stack has matured:

- **World-scale AR anchoring is real and productized.** Visual Positioning Systems (VPS) combine GPS with vision-based localization to place content far more reliably than GPS alone.
- **Persistent, shareable AR at real-world locations is shipping.** Modern AR platforms can lock content to places in a way that multiple people can reliably see over time.
- **Consumers and creators are being trained for location-anchored AR.** Place-anchored AR content creation is becoming mainstream.
- **Spatial computing hardware is moving from "demo" to "platform."** Headsets and smart glasses are evolving into everyday computing surfaces.

CANVS is designed to become **glass-native**: as AR glasses and spatial computers transition into everyday devices, CANVS becomes an always-available layer—less like an app, more like a **new default interface for place**.

---

## 1. Manifesto: The End of the Feed, the Beginning of the World

We are building the **Internet of Places**.

Today's social platforms are optimized for **infinite scrolling**, not for human life. They isolate us inside algorithmic loops and replace lived reality with mediated content.

CANVS flips the direction of attention:

- The feed is not the home screen. **The world is.**
- Content is not something you "go find." It's something you **encounter**, because you are there.
- Meaning is not manufactured by engagement hacks. Meaning is **in context**.

A story about a sunset is powerful anywhere.
A story about a sunset becomes *inevitable* when you're sitting in the exact place it happened—at the same angle, the same horizon line, the same wind.

**Vision:** CANVS is the social operating layer for spatial computing.
When the world becomes a canvas, CANVS provides the paint.

---

## 2. The Problem: Context Loss and the "Ghost Event"

**Things happen at places.**
But digital memory is usually detached from the physical world.

A first kiss. A perfect skate trick. A protest that changed someone's life. A conversation that flipped a career. A hidden café that felt like finding oxygen.

Then the moment ends—and the meaning becomes invisible.

**Status quo:**
Someone stands at that place two weeks later and sees… concrete. The emotion is gone. The story exists somewhere in a cloud account, if at all. It's not "there." It's nowhere.

**The gap:**
We walk through a world full of invisible meaning, unable to perceive the human layers that already exist all around us.

---

## 3. The Solution: Persistent Emotional Anchoring

CANVS makes moments **spatially persistent**.

Not as a gimmick, but as a new medium:
**Place becomes the index.**

CANVS enables:

- **Reality Time Capsules:** content (text, audio, video, 3D captures, sketches) pinned to real-world locations so future visitors can "open" the moment where it happened.
- **Asynchronous presence:** you can experience a moment later, not by "watching a video," but by seeing the memory **in situ**, aligned to the geometry of the world.

This depends on a real technical foundation: **world-locked anchoring**.

- GPS alone often breaks immersion due to drift and urban multipath.
- Modern stacks combine GPS with vision-based localization (VPS) and mapping for stable placement.
- Reliable persistence requires multi-tier anchoring, re-localization, and confidence-aware rendering.

---

## 4. The Product Thesis: "The Spatial Social Layer"

CANVS is not:

- a traditional social network (feed-first)
- a maps app (utility-first)
- a game (loop-first)

CANVS is a new primitive:

### The world as a browsable interface

A **Spatial Browser** that lets you "read" places the way you read websites.

If the 1990s internet was made of pages and links, the spatial internet is made of:

- **Places**
- **Anchors**
- **Layers**
- **Memories**
- **Paths**
- **Social context**
- **AI mediation**

---

## 5. Core Experience: The Spatial Browser

### 5.1 Three modes (one mental model)

1. **AR Mode ("Magic Window / Glass View")**
   You look at the world and see location-anchored content where it belongs.

2. **Map Mode ("Spatial Radar")**
   You see nearby layers, hotspots, and trails. Map is not the product—it's the minimap.

3. **Time Mode ("Temporal Scrub")**
   Slide through time to see what happened here: yesterday, last summer, 10 years ago.

### 5.2 The fundamental interaction: "Look → Understand → Act"

CANVS is built around "micro-encounters":

- see a story
- feel something
- reply, add context, or create your own layer
- move on, carrying the place with you

The goal is not infinite consumption.
The goal is **meaningful place interactions**.

**North Star metric proposal:**
**MPI/week = Meaningful Place Interactions per user per week**
(Opening a capsule, leaving a voice note, contributing to a utility marker, participating in a local thread, etc.)

---

## 6. Core Building Blocks: Spatial Primitives

### A. Pins

Simple anchors: notes, photos, audio, links, "hidden menu" tips, warnings, micro-stories.

### B. Bubbles (Group Memory Objects)

A shared container anchored to a place.

Examples:

- "We used to meet here every Friday."
- "This bench is where she told me yes."
- "We found this spot during our first week in this city."

### C. Time Capsules

Richer artifacts: multi-media + 3D capture + timeline.

### D. Trails

A sequence of anchors that forms a narrative route:

- "My break-up walk."
- "Best street art within 12 minutes."
- "The city through immigrant food."
- "A grief trail for remembrance."

### E. Drops (Geo-fenced Releases)

Music, artwork, collectibles, or messages that only unlock at a location and time.

### F. Portals

A place anchored to another place via story logic:

- "If you liked this, go to that."
- "This spot is the sibling of that spot."

---

## 7. Deep-Tech Foundation: How This Becomes Real

### 7.1 World-scale localization: GPS is not enough

**Reality:** GPS drift breaks immersion.

Modern AR stacks solve this via **visual localization** and mapping.

**Design implication for CANVS:**
Build a **multi-tier anchoring strategy**:

1. **Coarse localization** (GPS / map alignment) for discovery and approximate placement
2. **VPS localization** (when available) for world alignment
3. **Local SLAM anchoring** for stable, low-jitter placement in the user's immediate session
4. **Re-localization & drift correction** for persistence across time and devices

### 7.2 Technology Stack

The AR technology landscape has matured significantly. Here's what's production-ready today:

| Provider | Coverage | Accuracy | Best For |
|----------|----------|----------|----------|
| **Google ARCore Geospatial** | 100+ countries | 1-5 meters | Global coverage, wide device support |
| **Niantic Lightship VPS** | 1M+ activated locations | Centimeter-level | High-precision at key venues |
| **Apple ARKit Location Anchors** | ~50 cities | Sub-meter | iOS premium experience |
| **Unity AR Foundation 5.x** | Cross-platform | Platform-dependent | Single codebase development |

**Recommended Multi-Provider Strategy for CANVS:**
1. **Primary**: Google ARCore Geospatial API (global coverage, free, proven at scale)
2. **Precision Layer**: Niantic Lightship VPS (centimeter accuracy at activated locations)
3. **Fallback**: GPS + compass + IMU (always available, graceful degradation)
4. **Indoor**: Custom venue mapping via Immersal or Niantic enterprise

### 7.3 The "AR Cloud" is the macro concept

The "AR Cloud" describes a persistent, spatially accurate digital copy of the world (a "digital twin") that enables shared AR experiences across users and time.

**CANVS interpretation:**
We don't need to own the entire AR Cloud. We need to own the **social meaning layer** that lives on top of it.

### 7.4 Positioning abstraction: "Anchor Runtime"

In practice, CANVS should treat positioning vendors as interchangeable backends.

CANVS creates its own stable concept:

- **CANVS Anchor ID** (a persistent identifier)
- **Anchor bundles** (multi-representation: lat/long/alt + visual features + local map fragments + constraints)
- **Confidence-aware rendering** (content fades in only when tracking confidence is sufficient)

### 7.5 3D capture becomes a native media type (not a luxury)

To "freeze" moments, CANVS should support **spatial capture formats**:

- Quick scan (phone LiDAR / photogrammetry)
- "Spatial clips" (short 3D snapshots)
- High-fidelity capture for creators

**Product implication:**
Time capsules evolve from "video pinned to a spot" into "walkable memory fragments."

### 7.6 Web-native distribution is a force multiplier

"Open in browser" becomes a growth lever: a location-locked experience shared via link, not installation.

### 7.7 Hardware agnosticism is not optional

Spatial computing hardware is diversifying (headsets, AR glasses, smart glasses with displays).

CANVS should architect for **portable XR**:

- Use standards where possible.
- Treat the phone as the bootstrapping device, but maintain a "glass-first" UX philosophy.

---

## 8. Market Opportunity: Why This, Why Now

### 8.1 Market Size & Growth

The convergence of AR, location services, and social media creates a massive opportunity:

| Market Segment | 2025 | 2030 (Projected) | CAGR |
|----------------|------|------------------|------|
| Global AR Market | $83.65B | $599.59B | 37.9% |
| Location-Based Services | $56.23B | $172.97B | 25.35% |
| Mobile AR Market | $94.82B | $327.7B | 30.84% |
| UGC Platform Market | $9.0B | $72.32B | 29.82% |

**Key Insight:** The total addressable market exceeds **$800 billion by 2030**.

### 8.2 Cultural Timing

We are at a cultural inflection point:

- **73% of Gen Z** report digital exhaustion despite 7.2 hours daily online
- **62%** struggle to build meaningful relationships through current platforms
- **41%** of Americans are actively reducing screen time
- **32%** report social media fatigue - demand for new experiences is real

### 8.3 Proven Model at Scale

Location-based AR is not speculative:

- **Pokemon GO**: $8+ billion lifetime revenue, 100M+ users, 40-minute average daily sessions
- **Snap Map**: 400M+ monthly active users, 8 billion AR lens plays per day
- **Google Maps Live View**: Billions of users with AR navigation

The technology works. The user behaviors exist. The gap is a **social layer that isn't a game**.

### 8.4 Why Now: The Strategic Window

**Timing factors that make 2026 the ideal launch window:**

1. **Technology Inflection**: ARKit 6, ARCore Geospatial, and Niantic VPS are mature and production-ready
2. **5G Maturity**: 60%+ global population coverage enables real-time location experiences
3. **AR Glasses Horizon**: 2-3 years before mainstream adoption creates urgency to build content networks
4. **Incumbent Gaps**: Niantic pivoted to enterprise (sold Pokemon GO for $3.5B), BeReal declined 40%, no dominant player in emotional location social
5. **Privacy Demand**: 78% of users have deleted apps over privacy concerns - opportunity for trust-first design

---

## 9. Competitive Landscape

### 9.1 Who's Playing in Location Social

| Platform | Users | Model | Gap CANVS Fills |
|----------|-------|-------|-----------------|
| **Snap Map** | 400M MAU | Real-time location sharing | No persistent content; shows WHERE not WHAT |
| **Pokemon GO** | 60M MAU | Location-based gaming | Gaming focus, not social-first |
| **Google Maps** | Billions | Utility + reviews | Transactional, not emotional |
| **Instagram Map** | Large | Content discovery by location | Location is feature, not focus |
| **Yelp** | 178M visitors | Business reviews | Business-focused, not social |

### 9.2 What's Missing in the Market

**No mainstream app lets users leave discoverable content at physical locations that persists over time.**

Current solutions are fragmented:
- Check-ins (Foursquare) → Check-in fatigue killed this
- Reviews (Yelp/Google) → Transactional, not emotional
- Location sharing (Snap Map) → Real-time only, no persistence
- Exploration (Randonautica) → Niche, no user content

### 9.3 Why Location Apps Have Failed Before

| App | Failure Mode | CANVS Lesson |
|-----|--------------|--------------|
| **Foursquare** | Split into two apps, lost social magic | Keep social core unified |
| **Yik Yak** | Anonymity + location = unmoderable | Identity and safety from day one |
| **Gowalla** | Feature war with Foursquare | Don't compete on same dimensions |
| **Google Glass** | "Glasshole" stigma, premature launch | Phone-first avoids wearable stigma |
| **BeReal** | Forced authenticity creates new anxiety | Context over gimmicks |

**Key Insight:** Proximity alone isn't compelling. Location must enhance genuine value—not be the sole value proposition.

---

## 10. LLM Agents as the "Reality Filter" (Not a Chatbot)

In a world where every place can hold content, the core product is not creation—it's **filtering**.

CANVS needs a personal AI layer that feels like:

- "my taste"
- "my friends"
- "my values"
- "my mental state"
- "my intent right now"

### 10.1 The Agent's job

- Summarize the layer you're in
- Surface what matters
- Prevent overwhelm
- Prevent harm
- Turn raw spatial data into *felt relevance*

### 10.2 Example features (agent-native)

- **Friend-memory surfacing:** "Your friend left a note here 3 years ago."
- **Emotion search:** "Show me places where people reported feeling calm."
- **Context compression:** Turn 400 nearby anchors into 5 meaningful options.
- **Path generation:** "Give me a 30-minute walk that ends somewhere optimistic."

### 10.3 Safety-aware personalization

The agent is also a safety filter:

- suppress stalking-like patterns
- reduce accidental over-sharing
- warn if a user is about to publish to a sensitive location context

(See "Safety & Governance" below.)

---

## 11. Emotional & Social Use Cases: Re-enchanting Reality

### Category 1: Shared Memories (Emotional Layer)

**1) The Skating Bubble**
Friends leave a group bubble at the rink. Years later, someone returns alone and opens it—hearing laughter and seeing spatial clips aligned to the ice.

**2) Sunset Stories**
A global atlas of romance: "Sit here at 19:42. Perfect angle."

**3) Grief & Remembrance**
Digital candles and memories anchored to meaningful places—lasting, revisitable, shareable with chosen people.

**4) Letters to Future Me**
A capsule you can only open when you physically return.

### Category 2: Hyper-Local Utility (Useful Layer)

**1) Surf Intelligence**
AR markers: hazards, entry points, wind advice.

**2) Hidden Menu Layer**
Recommendations pinned to a specific table or counter: "Order it this way."

**3) Accessibility Layer**
User-generated accessibility notes anchored precisely: step-free entrances, quiet hours, safe seating, lighting warnings.

### Category 3: Urban Culture & Play (Creative Layer)

**1) Street Art Living Threads**
Discussions float *in front of* murals—timelines, artist credits, community response—without touching the wall.

**2) Flashmob Countdown / Location Drops**
Exclusive content appears when a place "activates" at a time.

**3) Civic Layer (Citizen Signals)**
Hazards, unsafe corners, mutual aid requests, neighborhood alerts.

---

## 12. Societal Impact: Why the World Needs This

### 12.1 Movement and "Touching Grass"

Location-based AR can drive real-world activity. CANVS generalizes that mechanism beyond a single game loop:

- content requires presence
- presence requires movement
- movement increases serendipity and social contact

**Market validation**: 180M+ Americans set outdoor recreation records in 2024 (80% participation rate). People want to be outside—they need reasons.

### 12.2 Economic revitalization

Location-anchored digital layers can improve discovery and drive attention to local businesses.

CANVS can become the "local discovery layer" that is emotional, not transactional.

**Partnership opportunities:**
- Tourism boards and destination marketing (AR tourism market: $29B → $109B by 2030)
- Local businesses and chambers of commerce
- Universities and campuses (32.9% dropout rate = engagement crisis)
- Music/entertainment venues (concert AR experiences)
- Museums and cultural institutions

### 12.3 The map data itself becomes strategic

Planet-scale spatial mapping is increasingly viewed as a core asset for future devices like smart glasses and robots.

CANVS rides that wave—while specializing in the **human meaning graph**.

---

## 13. Challenges & Mitigations

### 13.1 Technical Challenges

| Challenge | Impact | CANVS Mitigation |
|-----------|--------|------------------|
| GPS accuracy (urban canyons) | Content appears in wrong place | VPS fusion with graceful degradation |
| AR drift and stability | Objects float/jitter | Confidence-aware rendering; cloud anchors |
| Battery consumption | 2-hour sessions max in full AR | AR as enhancement, not requirement |
| Device fragmentation | Not all phones support AR | Core features work without AR |
| Development costs | $250K-$800K for complex AR | Cross-platform Unity; phased features |

### 13.2 User Adoption Barriers

| Barrier | Concern | CANVS Mitigation |
|---------|---------|------------------|
| Social awkwardness | "Glasshole" stigma | Phone-first (socially normalized) |
| Privacy concerns | Location tracking fears | Granular controls, privacy-by-design |
| Empty world problem | No content = no value | Atomic network launch; seed content |
| Network effects | Need users to create value | Solo value first; async social |

### 13.3 Business Challenges

| Challenge | Risk | CANVS Mitigation |
|-----------|------|------------------|
| Content moderation | Location-specific harm | Proactive moderation; property owner opt-out |
| Legal/property rights | Trespassing liability | Default to public spaces; clear ToS |
| Monetization uncertainty | No proven model for location social | Multiple revenue streams; creator economy |
| Data privacy regulations | GDPR/CCPA fines | Privacy-first architecture; over-compliance |

---

## 14. Trust, Safety, and Governance: The Layer Must Be Safe by Design

A spatial social layer amplifies both beauty and risk. The design must assume adversarial use.

### 14.1 Location privacy is high stakes

Location data can enable re-identification, inference of sensitive information, and physical threats.

**CANVS principle:**
Precision is a privilege, not a default.

### 14.2 Anti-stalking posture (non-negotiable)

**CANVS must implement:**

- private-by-default creation modes
- audience controls (self / friends / groups / public)
- proximity-based visibility limits
- strong reporting and rapid takedown
- "shadow banning" for suspicious behavioral patterns
- location obfuscation options ("near here" instead of exact)
- hard blocks that prevent re-appearance in shared spaces

### 14.3 Property, nuisance, and crowd externalities

Location-based experiences can generate real-world conflict.

**CANVS mitigation model:**

- **Private Space Shield:** strong exclusion zones and owner claims
- **Noise budgets:** limit visibility/activation of high-traffic anchors
- **Event throttles:** prevent "stampede mechanics" near residences
- **Local governance:** trusted community moderators, verified stewards
- **"Good citizen" design:** discourage congregating mechanics in sensitive places

**Lesson from Pokemon GO:** $4M settlement over trespassing. Property owner opt-out must exist from day one.

### 14.4 Moderation needs to be spatially aware

Unlike a feed, harmful content in CANVS is **attached to a place**. Moderation needs:

- geofenced rules (schools, hospitals, memorial sites)
- content type constraints by zone
- age gating
- contextual integrity (e.g., memorial vs nightlife area)

---

## 15. Monetization: Non-Intrusive, Spatial-Native, Opt-In

CANVS monetizes *without becoming a billboard apocalypse*.

### 15.1 Contextual Advertising (Privacy-First)

Location-based advertising can be privacy-first and effective:
- Contextual ads get 50% more clicks than behavioral
- 79% of consumers prefer contextual vs behavioral ads
- Global contextual advertising market: $562.1B by 2030

**CANVS approach**: Contextual targeting uses place content, not user tracking.

### 15.2 Spatial-native brand objects

Not popups. **Objects with physical logic**:

- collectibles
- AR mini-experiences
- limited drops
- "try before you buy" overlays
- "story objects" that belong to a location

### 15.3 Local business toolkit (the "Digital Footfall Engine")

- claim your place
- publish offers as spatial objects
- enable "community moments" (e.g., secret menu, local trivia)
- get aggregated analytics (privacy-preserving)

### 15.4 Events as high-intensity loops

CANVS can enable "micro-events" at neighborhood scale and "macro-events" for cities.

### 15.5 Premium

- personal memory vaults
- high-fidelity time capsules
- private group spaces
- advanced AI filters
- creator tools (capture, editing, moderation features)

### 15.6 Creator Economy

Enable content creators to monetize:
- Tipping and appreciation features
- Exclusive experience access
- Brand collaboration tools

---

## 16. Strategic Roadmap: Mobile-First, Then Glass-Native

### The Phased Approach

CANVS will be built in two major phases, recognizing that AR glasses are 2-4 years from mainstream adoption while mobile AR is production-ready today:

```
Phase 1: Mobile App Foundation
    ↓
Phase 2: Glass-Native Transition
```

**Strategic Rationale:**
- **Billions** of AR-capable smartphones are deployed today
- AR glasses (Apple, Meta, Google) arriving 2026-2029 as early-adopter products
- **2-3 year window** to build content networks and user habits before hardware shift
- Mobile establishes the data assets, social graphs, and behaviors that transfer to glasses

---

### Phase 1: Mobile App MVP

**Objective:** Prove the core loop; establish content networks; build user base.

#### 1A: Core Mobile Features

**Map Mode (Primary Experience)**
- Discover nearby CANVS content on an interactive map
- Filter by type: memories, recommendations, community notes, trails
- See content density "heat maps" for exploration
- Non-AR native - works on any smartphone

**Creation Tools (Mobile-First)**
- Pin text, photos, audio, video to locations
- Simple capture: point phone, record, anchor
- Privacy controls: public / friends / groups / self
- Time-lock options for future reveal

**AR Mode (Enhancement Layer)**
- Optional AR view using ARKit/ARCore
- See content floating at anchor points
- Walk toward content to "approach" it
- 10-30 second interaction design (not continuous)
- Graceful degradation when tracking confidence is low

**Social Features**
- Friend connections (import from contacts)
- Follow specific places or creators
- Activity feed: what friends created/discovered
- Async interaction: reply to content at locations you visit later

#### 1B: Technical Foundation

- **Multi-provider positioning**: ARCore Geospatial (primary), GPS (fallback)
- **Cloud anchor system**: Persistent content across users and time
- **Confidence-aware rendering**: Content appears when positioning is reliable
- **Battery optimization**: Intelligent polling; AR as opt-in enhancement
- **Device capability detection**: Graceful feature adaptation

#### 1C: Launch Strategy

**Atomic Network Approach** (learn from Cold Start Problem):
1. Launch in **one neighborhood** with content density, not global with emptiness
2. Partner with local venues for initial content seeding
3. Import interesting public locations (landmarks, parks, art)
4. Reward early users with "Founding Member" status
5. Expand neighborhood by neighborhood, city by city

**Initial Target Markets:**
- University campuses (captive audience, high engagement potential)
- Tourist destinations (tourism boards as partners)
- Music/entertainment venues (concert experiences)
- Neighborhoods with strong local identity

**Success Metrics:**
- MPI/week (Meaningful Place Interactions per user per week)
- Content density per square km in active areas
- Week 1 / Week 4 / Week 12 retention
- Time to first content creation
- AR mode adoption rate (enhancement, not requirement)

---

### Phase 1.5: Scale & Learn (2027)

**Objective:** Expand coverage; introduce AI filtering; build business relationships.

- **AI "Reality Filter" v1**: summarization, semantic search, friend-memory surfacing
- **Trails, drops, portals**: Richer content primitives
- **Local business claims**: Venue dashboard and basic analytics
- **Creator marketplace**: Early tools for content monetization
- **Web-native sharing**: Location-locked experiences via link (WebAR for discovery)
- **Geographic expansion**: 10+ cities with meaningful content density

**Data Assets Being Collected:**
- User location patterns and preferences
- Venue/place metadata from user activity
- Social connection graphs tied to locations
- User-generated content anchored to millions of places
- Movement patterns and "moments" data

*These assets become critical for glasses-native experiences.*

---

### Phase 2: Glass-Native Transition (2029–2031)

**Objective:** Become the default spatial social layer across devices.

#### 2029: Early Glass Integration

- **visionOS app**: Ship for Apple Vision Pro (even with low adoption) for developer credibility
- **Android XR early access**: Position for Google/Samsung glasses launch
- **Snap Specs partnership**: Leverage Snap's 400M MAU Snap Map for spatial discovery
- **Always-on lightweight layer**: "Glanceable place context" UX
- **Audio-first features**: Voice check-ins, proximity notifications
- **Spatial audio cues**: Directional sound for content discovery

#### 2030: Platformization

- **Public SDK**: Third-party "place apps" can build on CANVS location layer
- **Verified civic layers**: Cities, museums, campuses as official content sources
- **Indoor positioning**: Venue partnerships for interior navigation
- **Enterprise tools**: Real estate, tourism, retail analytics (privacy-preserving)
- **Standards alignment**: Portable XR workflows for cross-platform content

#### 2031: The Spatial Social OS

- **Default "meaning layer"**: CANVS runs across phones, glasses, and future devices
- **Places become queryable**: "What should I know about this place?"
- **Emotionally legible world**: AI understands "vibe" of locations
- **The feed is obsolete**: Location and context replace algorithmic curation

---

### Hardware Timeline Alignment

| Year | Hardware State | CANVS Position |
|------|----------------|----------------|
| **2026** | Smart glasses (audio + camera); Meta leads | Mobile app launch; build content network |
| **2028** | Display glasses emerge ($300-800) | Scale mobile; begin glasses R&D |
| **~2029** | Apple/Google AR glasses launch | Ship glasses apps; establish ecosystem position |
| **~2029** | 43M+ AR devices projected | Multi-platform growth; platformization |
| **~2030** | AR glasses approach mainstream | Glass-native default; spatial social OS |

**Strategic Insight:** The race is for **data assets**, not hardware. Whoever has the best location intelligence, social graphs, and spatial content will power the glasses experiences of 2028-2030. Building on mobile NOW creates the foundation.

---

## 17. The Big Opportunity: Why This Can Become a Once-a-Decade Platform

The social internet has had multiple eras:

1. **Web pages** (static)
2. **Feeds** (social graphs + algorithmic distribution)
3. **Messaging** (private networks)
4. **Spatial** (place as interface)

CANVS is built for the spatial era.

The infrastructure is converging:

- AR anchoring stacks exist across major ecosystems
- The AR Cloud concept supports persistent shared experiences
- Spatial computing devices are accelerating beyond labs
- Location-based AR has demonstrated real-world behavior change at scale

This creates a window where a "spatial social layer" can become:

- **the default discovery interface for cities**
- **the default memory interface for human life**
- **the default coordination layer for communities**
- **the default canvas for creators**
- **the default AR layer for glasses**

### Why CANVS Can Win

**Perfect Storm of Conditions:**
1. **Technology Ready:** Mobile AR is mature, 5G is ubiquitous, ARKit/ARCore proven
2. **Cultural Moment:** Gen Z exhaustion with traditional social creates demand
3. **Market Gap:** Niantic pivot, BeReal decline, no dominant player in emotional location social
4. **Timing Window:** 2-3 years before AR glasses shift landscape
5. **Privacy Positioning:** First-mover in privacy-first location sharing

**Unique Positioning:**
CANVS occupies a space no one else is targeting:
- **Not transactional** (unlike Yelp, Google Maps)
- **Not gamified** (unlike Pokemon GO)
- **Not forced authenticity** (unlike BeReal)
- **Not surveillance-based** (unlike Facebook)

Instead: **Emotional, persistent, movement-encouraging, community-building, privacy-first**

---

## 18. Conclusion: Build the Layer

CANVS is not "another app."

It is a bet that the next interface is not a rectangle, not a feed, not a timeline.

It's the world.

A world where no moment is lost—because the place remembers.

**The strategy is clear:**

1. **Start mobile-first** — the technology is ready, the devices are deployed, the user behaviors are proven
2. **Build the content network** — every place with a memory becomes more valuable
3. **Establish the social graph** — connections rooted in shared places
4. **Prepare for glasses** — architect for the transition that will reshape computing
5. **Own the meaning layer** — not the AR Cloud, but what makes it matter to humans

---

## Appendix A: Research Sources

### Market Research
- [Grand View Research - AR Market](https://www.grandviewresearch.com/industry-analysis/augmented-reality-market)
- [Fortune Business Insights - Location-Based Services](https://www.fortunebusinessinsights.com/industry-reports/location-based-services-market-101060)
- [SNS Insider - Mobile AR Market](https://www.globenewswire.com/news-release/2025/10/28/3175180/0/en/Mobile-Augmented-Reality-Market-Size-to-Surpass-USD-327-7-Billion-by-2032-Rising-at-a-CAGR-of-30-84-Report-by-SNS-Insider.html)

### Technology & Platforms
- [Google ARCore Geospatial API](https://developers.google.com/ar/develop/geospatial)
- [Niantic Lightship VPS](https://lightship.dev/docs/ardk/features/lightship_vps/)
- [Apple ARKit Documentation](https://developer.apple.com/documentation/arkit)

### Competitive Analysis
- [Business of Apps - Pokemon GO Statistics](https://www.businessofapps.com/data/pokemon-go-statistics/)
- [Snap Map 400M MAU](https://techcrunch.com/2025/05/07/snap-map-reaches-new-milestone-of-400m-monthly-active-users/)

### Gen Z & Social Trends
- [Human8 - Gen Z Digital Exhaustion 2025](https://www.wearehuman8.com/blog/gen-z-in-2025-navigating-digital-exhaustion-in-a-digitally-native-world/)
- [Cropink - Social Media Mental Health Statistics](https://cropink.com/social-media-mental-health-statistics)

### AR Glasses Timeline
- [Glass Almanac - AR Glasses 2026](https://glassalmanac.com/7-ar-glasses-and-platforms-in-2026-that-could-surprise-consumers-what-changes/)
- [IDC - AR/VR Market Insights](https://www.idc.com/promo/arvr/)

### Historical Lessons
- [Slidebean - What Happened to Foursquare](https://slidebean.com/story/what-happened-to-foursquare)
- [Harvard JSEL - Pokemon Go Class Action](https://journals.law.harvard.edu/jsel/2019/04/pokemon-go-class-action-settles-as-augmented-reality-legal-questions-remain/)
- [A16Z - The Cold Start Problem](https://a16z.com/books/the-cold-start-problem/)

---
